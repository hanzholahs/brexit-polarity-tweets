{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Brexit Polarity Tweets - Text Classification\n",
    "\n",
    "Reference for feature selection and dimensionality reduction: https://arxiv.org/pdf/1905.02845.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Manipulation and Visualization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "\n",
    "# ML Tools\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, RocCurveDisplay\n",
    "from sklearn.metrics import recall_score, roc_auc_score\n",
    "\n",
    "# ML Models\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import tensorflow as tf\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# settings\n",
    "N_ROWS     = 1_000 # `None` to import all rows\n",
    "TEST_SPLIT = 0.2\n",
    "\n",
    "# paths to extracted features\n",
    "PATH_PREPROCESSED_TRAIN = \"./data/preprocessed/train/\"\n",
    "PATH_PREPROCESSED_TEST = \"./data/preprocessed/test/\"\n",
    "PATH_FEATURE_TRAIN = \"./data/features/train/\"\n",
    "PATH_FEATURE_TEST = \"./data/features/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "sia = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tweet(filepath):    \n",
    "    tweets = []\n",
    "    \n",
    "    with open(filepath, \"r\") as f:\n",
    "        for tweet in f:\n",
    "            tweets.append(tweet.replace(\"\\n\", \"\"))\n",
    "    \n",
    "    return pd.Series(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment score-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5138003163103924"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = read_tweet(PATH_PREPROCESSED_TEST + \"0-clean.txt\")\n",
    "targets = read_tweet(PATH_PREPROCESSED_TEST + \"0-targets.txt\")\n",
    "\n",
    "polarity = []\n",
    "for tweet in tweets:\n",
    "    polarity.append(sia.polarity_scores(tweet)[\"compound\"])\n",
    "polarity = pd.Series(polarity) > 0.5\n",
    "\n",
    "# evaluate baseline model\n",
    "y_pred = polarity.apply(lambda x: \"Pro\" if x else \"Anti\")\n",
    "accuracy_score(targets, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest using Sentiment Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5292332023876333"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit baseline model\n",
    "tweets = read_tweet(PATH_PREPROCESSED_TRAIN + \"0-clean.txt\")\n",
    "targets = read_tweet(PATH_PREPROCESSED_TRAIN + \"0-targets.txt\")\n",
    "\n",
    "polarity = []\n",
    "for tweet in tweets:\n",
    "    polarity.append(sia.polarity_scores(tweet))\n",
    "polarity = pd.DataFrame(polarity)\n",
    "\n",
    "baseline = RandomForestClassifier()\n",
    "baseline.fit(polarity, targets)\n",
    "\n",
    "\n",
    "# evaluate baseline model\n",
    "tweets = read_tweet(PATH_PREPROCESSED_TEST + \"0-clean.txt\")\n",
    "targets = read_tweet(PATH_PREPROCESSED_TEST + \"0-targets.txt\")\n",
    "\n",
    "polarity = []\n",
    "for tweet in tweets:\n",
    "    polarity.append(sia.polarity_scores(tweet))\n",
    "polarity = pd.DataFrame(polarity)\n",
    "\n",
    "y_pred = baseline.predict(polarity)\n",
    "accuracy_score(targets, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature-based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(PATH_FEATURE_TRAIN + \"1-clean-nostw.csv\")\n",
    "targets = read_tweet(PATH_PREPROCESSED_TRAIN + \"0-targets.txt\")\n",
    "\n",
    "# fit baseline model\n",
    "baseline = RandomForestClassifier()\n",
    "baseline.fit(tweets, targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = pd.read_csv(PATH_FEATURE_TEST + \"1-clean-nostw.csv\")\n",
    "targets = read_tweet(PATH_PREPROCESSED_TEST + \"0-targets.txt\")\n",
    "\n",
    "# evaluate baseline model\n",
    "y_pred = baseline.predict(tweets)\n",
    "accuracy_score(targets, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    KNeighborsClassifier(),\n",
    "    LogisticRegression(),\n",
    "    RandomForestClassifier(),\n",
    "    GradientBoostingClassifier(),\n",
    "    AdaBoostClassifier(),\n",
    "    XGBClassifier()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a dictionary to store each algorithm performance\n",
    "cv_scores = {}\n",
    "\n",
    "for model in models:\n",
    "    score = cross_val_score(model, X_train, y_train, cv = 5, n_jobs = -1)\n",
    "    cv_scores[model.__class__.__name__] = np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = np.array(list(cv_scores.keys()))\n",
    "model_scores = np.array([np.mean(scores) for scores in cv_scores.values()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scores_percent = list(map(lambda x: f\"{x*100:.2f} %\", model_scores))\n",
    "\n",
    "pd.DataFrame({\"Model Name\": model_names, \"Score\": model_scores_percent}) \\\n",
    "    .sort_values(by = 'Score', ascending = False) \\\n",
    "    .reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorting_index = np.argsort(model_scores)\n",
    "\n",
    "plt.barh(y = model_names[sorting_index], width = model_scores[sorting_index])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
