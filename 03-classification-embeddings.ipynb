{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper functions\n",
    "def read_tweet(filepath):\n",
    "    import pandas as pd\n",
    "    tweets = []\n",
    "    with open(filepath, \"r\") as f:\n",
    "        for tweet in f:\n",
    "            tweets.append(tweet.replace(\"\\n\", \"\"))\n",
    "    return pd.Series(tweets)\n",
    "\n",
    "tweets = read_tweet(\"data/preprocessed/train/\" + \"1-clean.txt\")[:50000]\n",
    "targets = read_tweet(\"data/preprocessed/train/\" + \"0-targets.txt\")[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "targets = label_encoder.fit_transform(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectorizer_and_embedding(vocab, word_vectors, seq_length):\n",
    "    assert len(vocab) == len(word_vectors)\n",
    "    vocab_size  = len(vocab)\n",
    "    vector_size = len(word_vectors[0])\n",
    "    \n",
    "    vectorizer = TextVectorization(output_sequence_length = seq_length,\n",
    "                                   output_mode = 'int',\n",
    "                                   vocabulary  = vocab)\n",
    "    \n",
    "    embedding_weights = tf.keras.initializers.Constant(np.concatenate([\n",
    "        np.zeros((2, vector_size)), # for padding and oov\n",
    "        word_vectors\n",
    "    ]))\n",
    "    \n",
    "    embedding = Embedding(vocab_size + 2, # for padding and oov\n",
    "                          vector_size,\n",
    "                          trainable  = False,\n",
    "                          weights    = embedding_weights)\n",
    "    \n",
    "    return vectorizer, embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer, embedding = get_vectorizer_and_embedding(model_fasttext.wv.index_to_key,\n",
    "                                                     model_fasttext.wv.vectors,\n",
    "                                                     SEQ_LENGTH)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
